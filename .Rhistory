hc_annotations(labels = list(x = 10, y = 200, xAxis = 0, yAxis = 0), text = "Middle")
library(highcharter)
ok <- 50
good <- 20
perfect <- 10
highchart(width = 600, height = 400) %>%
hc_chart(type = "solidgauge", marginTop = 50) %>%
hc_tooltip(borderWidth = 0,backgroundColor = 'none',shadow = FALSE,style = list(fontSize = '16px'),
pointFormat = '<span style="font-size:1.5em; color: {point.color}; font-weight: bold">{point.y}&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;{series.name}</span>',
positioner = JS("function (labelWidth, labelHeight) {return {x: 176,y: 200};}")) %>%
hc_pane(startAngle = 0,endAngle = 360,
background = list(
list(outerRadius = '112%',innerRadius = '88%',backgroundColor = JS("Highcharts.Color('#f0b4b5').setOpacity(0.1).get()"),borderWidth =  0),
list(outerRadius = '87%',innerRadius = '63%',backgroundColor = JS("Highcharts.Color('#f0b4b5').setOpacity(0.1).get()"),borderWidth = 0),
list(outerRadius = '62%',innerRadius =  '38%',backgroundColor = JS("Highcharts.Color('#f0b4b5').setOpacity(0.1).get()"),borderWidth = 0))) %>%
hc_yAxis(min = 0,max = 100,lineWidth = 0,tickPositions = list()) %>%
hc_plotOptions(solidgauge = list(borderWidth = '34px',dataLabels = list(enabled = FALSE),linecap = 'round',stickyTracking = FALSE)) %>%
hc_add_series(name = "With DOI",borderColor = '#fae6e8',data = list(list(color = '#e43235',radius = "100%",innerRadius = "100%",y = ok))) %>%
hc_add_series(name = "With abstract",borderColor = '#f0b4b5',data = list(list(color = '#e43235',radius = "75%",innerRadius = "75%",y = good))) %>%
hc_add_series(name = "Complete",borderColor = '#e43235',data = list(list(color = '#e43235',radius = "50%",innerRadius = "50%",y = perfect))) %>%
hc_annotations(list(labels = list(x = 10, y = 200, xAxis = 0, yAxis = 0), text = "Middle"))
highchart(width = 600, height = 400) %>%
hc_chart(type = "solidgauge", marginTop = 50) %>%
hc_tooltip(borderWidth = 0,backgroundColor = 'none',shadow = FALSE,style = list(fontSize = '16px'),
pointFormat = '<span style="font-size:1.5em; color: {point.color}; font-weight: bold">{point.y}&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;{series.name}</span>',
positioner = JS("function (labelWidth, labelHeight) {return {x: 176,y: 200};}")) %>%
hc_pane(startAngle = 0,endAngle = 360,
background = list(
list(outerRadius = '112%',innerRadius = '88%',backgroundColor = JS("Highcharts.Color('#f0b4b5').setOpacity(0.1).get()"),borderWidth =  0),
list(outerRadius = '87%',innerRadius = '63%',backgroundColor = JS("Highcharts.Color('#f0b4b5').setOpacity(0.1).get()"),borderWidth = 0),
list(outerRadius = '62%',innerRadius =  '38%',backgroundColor = JS("Highcharts.Color('#f0b4b5').setOpacity(0.1).get()"),borderWidth = 0))) %>%
hc_yAxis(min = 0,max = 100,lineWidth = 0,tickPositions = list()) %>%
hc_plotOptions(solidgauge = list(borderWidth = '34px',dataLabels = list(enabled = FALSE),linecap = 'round',stickyTracking = FALSE)) %>%
hc_add_series(name = "With DOI",borderColor = '#fae6e8',data = list(list(color = '#e43235',radius = "100%",innerRadius = "100%",y = ok))) %>%
hc_add_series(name = "With abstract",borderColor = '#f0b4b5',data = list(list(color = '#e43235',radius = "75%",innerRadius = "75%",y = good))) %>%
hc_add_series(name = "Complete",borderColor = '#e43235',data = list(list(color = '#e43235',radius = "50%",innerRadius = "50%",y = perfect))) %>%
hc_add_annotation(xValue = 100, yValue = 200, title = list(text = 'test'))
library(highcharter)
ok <- 50
good <- 20
perfect <- 10
highchart(width = 600, height = 400) %>%
hc_chart(type = "solidgauge", marginTop = 50) %>%
hc_tooltip(borderWidth = 0,backgroundColor = 'none',shadow = FALSE,style = list(fontSize = '16px'),
pointFormat = '<span style="font-size:1.5em; color: {point.color}; font-weight: bold">{point.y}&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;{series.name}</span>',
positioner = JS("function (labelWidth, labelHeight) {return {x: 176,y: 200};}")) %>%
hc_pane(startAngle = 0,endAngle = 360,
background = list(
list(outerRadius = '112%',innerRadius = '88%',backgroundColor = JS("Highcharts.Color('#f0b4b5').setOpacity(0.1).get()"),borderWidth =  0),
list(outerRadius = '87%',innerRadius = '63%',backgroundColor = JS("Highcharts.Color('#f0b4b5').setOpacity(0.1).get()"),borderWidth = 0),
list(outerRadius = '62%',innerRadius =  '38%',backgroundColor = JS("Highcharts.Color('#f0b4b5').setOpacity(0.1).get()"),borderWidth = 0))) %>%
hc_yAxis(min = 0,max = 100,lineWidth = 0,tickPositions = list()) %>%
hc_plotOptions(solidgauge = list(borderWidth = '34px',dataLabels = list(enabled = FALSE),linecap = 'round',stickyTracking = FALSE)) %>%
hc_add_series(name = "With DOI",borderColor = '#fae6e8',data = list(list(color = '#e43235',radius = "100%",innerRadius = "100%",y = ok))) %>%
hc_add_series(name = "With abstract",borderColor = '#f0b4b5',data = list(list(color = '#e43235',radius = "75%",innerRadius = "75%",y = good))) %>%
hc_add_series(name = "Complete",borderColor = '#e43235',data = list(list(color = '#e43235',radius = "50%",innerRadius = "50%",y = perfect))) %>%
hc_add_annotation(labels = list(
list(
point = list(
xAxis = 0,
yAxis = 0,
x = datetime_to_timestamp(as.Date("2017/01/02")),
y = 1.5
))), title = list(text = 'test'))
runApp('inst/shiny-examples/bibfix')
runApp('inst/shiny-examples/bibfix')
runApp('inst/shiny-examples/bibfix')
runApp('inst/shiny-examples/bibfix')
setwd("~/OneDrive - SEI/ESHackathon/4.Remote 2020/bibfix/inst/shiny-examples/bibfix")
rsconnect::deployApp()
install.packages("rsconnect")
rsconnect::deployApp()
shiny::runApp('inst/shiny-examples/bibfix')
data <- read.csv('inst/extdata/data.csv')
if (is.data.frame(data) == FALSE){
stop('Please ensure the input object is a data frame')
}
#add missing columns where necessary (ensures build below works even if fields not present)
if(is.null(data$source_type) == TRUE){data$source_type <- NA}
if(is.null(data$author) == TRUE){data$author <- NA}
if(is.null(data$year) == TRUE){data$year <- NA}
if(is.null(data$title) == TRUE){data$title <- NA}
if(is.null(data$journal) == TRUE){data$journal <- NA}
if(is.null(data$volume) == TRUE){data$volume <- NA}
if(is.null(data$issue) == TRUE){data$issue <- NA}
if(is.null(data$start_page) == TRUE){data$start_page <- NA}
if(is.null(data$end_page) == TRUE){data$end_page <- NA}
if(is.null(data$abstract) == TRUE){data$abstract <- NA}
if(is.null(data$doi) == TRUE){data$doi <- NA}
if(is.null(data$publisher) == TRUE){data$publisher <- NA}
if(is.null(data$url) == TRUE){data$url <- NA}
if(is.null(data$notes) == TRUE){data$notes <- NA}
if(is.null(data$database) == TRUE){data$database <- NA}
if(is.null(data$AN) == TRUE){data$AN <- NA}
if(is.null(data$M1) == TRUE){data$M1 <- NA}
View(data)
#create RIS file
ris <- paste(paste0('\n',
'TY  - ', data$source_type, '\n',
'AU  - ', data$author, '\n',
'TI  - ', data$title, '\n',
'PY  - ', data$year, '\n',
'AB  - ', data$abstract, '\n',
'SP  - ', data$start_page, '\n',
'EP  - ', data$end_page, '\n',
'JF  - ', data$journal, '\n',
'VL  - ', data$volume, '\n',
'IS  - ', data$issue, '\n',
'DO  - ', data$doi, '\n',
'UR  - ', data$url, '\n',
'PB  - ', data$publisher, '\n',
'N1  - ', data$notes, '\n',
'M1  - ', data$M1, '\n',
'DB  - ', data$DB, '\n',
'AN  - ', data$AN, '\n',
'ER  - '),
collapse = '\n')
runApp('inst/shiny-examples/bibfix')
#replace NAs with ''
data[data==NA]=''
View(data)
#replace NAs with ''
data[is.na(data)==TRUE]=''
runApp('inst/shiny-examples/bibfix')
file <- file.choose()
refs <- synthesisr::read_refs(file)
refs$intID <- as.numeric(rownames(refs))
#store original data for additional column extraction later
orig_refs <- refs
####Tidy and subset####
#if vital columns missing, replace with NAs
if(is.null(refs$source_type) == TRUE){refs$source_type <- NA}
if(is.null(refs$author) == TRUE){refs$author <- NA}
if(is.null(refs$year) == TRUE){refs$year <- NA}
if(is.null(refs$title) == TRUE){refs$title <- NA}
if(is.null(refs$journal) == TRUE){refs$journal <- NA}
if(is.null(refs$volume) == TRUE){refs$volume <- NA}
if(is.null(refs$issue) == TRUE){refs$issue <- NA}
if(is.null(refs$start_page) == TRUE){refs$start_page <- NA}
if(is.null(refs$end_page) == TRUE){refs$end_page <- NA}
if(is.null(refs$abstract) == TRUE){refs$abstract <- NA}
if(is.null(refs$doi) == TRUE){refs$doi <- NA}
if(is.null(refs$publisher) == TRUE){refs$publisher <- NA}
if(is.null(refs$url) == TRUE){refs$url <- NA}
#replace Google Scholar incomplete fields based on presence of ellipsis '…'
refs[] <- lapply(refs, function(x) replace(x, grep("[…]", x), NA))
#if abstracts selected to be replaced, then replace with NA
if(replace_abstracts == TRUE){refs$abstract <- NA}
#select vital columns for searching
refs <- refs[c('source_type', "author", "year", "title", "journal", "volume", "issue", "start_page", "end_page", "abstract", "doi", "publisher", "url", "intID")]
#convert all columns to character strings
refs <- dplyr::mutate_all(refs, as.character)
#convert all 'NA's to NAs
refs[refs=="NA"]=NA
#subset records missing data
#create vectors of missing data for each row
refs$missing_data <- ''
for(i in 1:nrow(refs)){
row <- refs[i,]
missingCols <- paste0(names(refs)[which(is.na(row) == TRUE)], collapse = '; ')
refs$missing_data[i] <- missingCols
}
#subset based on missing data
missing_refs <- subset(refs, missing_data != '')
non_missing <- subset(refs, missing_data == '')
missing_refs <- dplyr::select(missing_refs, -c(missing_data))
non_missing <- dplyr::select(non_missing, -c(missing_data))
refs <- dplyr::select(refs, -c(missing_data))
####End Tidy and subset####
####DOI section####
#subset records with a DOI (easier to search)
doi_refs <- missing_refs[!is.na(missing_refs$doi),]
if(nrow(doi_refs)==0){
doi_refs <- NULL
} else {
#find missing records with DOI on Open Alex
#search for dois
doi_input <- data.frame(ids = doi_refs$doi,
type = 'doi')
df1 <- data.frame()
for (i in 1:length(doi_input$ids)){
query_work <- oaQueryBuild(
identifier = paste0("doi:https://doi.org/", doi_input$ids[i]),
entity = "works"
)
res <- oaApiRequest(
query_url = query_work
)
if(length(unlist(res))==0){
df1 <- df1
} else {
df1 <- dplyr::bind_rows(df1, oa2df(res, entity = "works"))
}
}
#Tidy results df
#rename result dataframe columns to match inputs
names(df1) <- sub('TI', 'title', names(df1))
names(df1) <- sub('AB', 'abstract', names(df1))
names(df1) <- sub('SO', 'journal', names(df1))
names(df1) <- sub('PU', 'publisher', names(df1))
names(df1) <- sub('PY', 'year', names(df1))
names(df1) <- sub('DI', 'doi', names(df1))
names(df1) <- sub('DT', 'source_type', names(df1))
names(df1) <- sub('volume', 'volume', names(df1))
names(df1) <- sub('issue', 'issue', names(df1))
names(df1) <- sub('first_page', 'start_page', names(df1))
names(df1) <- sub('last_page', 'end_page', names(df1))
names(df1) <- sub('URL', 'url', names(df1))
#remove df$doi URL stem
df1$doi <- gsub('https://doi.org/', '', df1$doi)
#remove irrelevant columns from df1 results
df1 <- dplyr::select(df1, c(author, year, title, journal, volume, issue, start_page, end_page, publisher, doi, abstract, source_type, url))
#collapse authors list
new_author <- list()
for (i in 1:length(df1$author)) {
new_author <- unlist(c(new_author, paste0(df1$author[[i]]$au_name, collapse = '; ')))
}
df1$author <- new_author
#lookup missing information
#lookup authors
doi_refs <- doi_refs %>%
dplyr::left_join(df1, by = c("doi")) %>%
dplyr::mutate(author = ifelse(is.na(author.x), author.y, author.x)) %>%
dplyr::select(-c(author.x, author.y)) %>%
dplyr::select(-c(contains('.y')))
names(doi_refs) <- sub('.x', '', names(doi_refs))
#lookup title
doi_refs <- doi_refs %>%
dplyr::left_join(df1, by = c("doi")) %>%
dplyr::mutate(title = ifelse(is.na(title.x), title.y, title.x)) %>%
dplyr::select(-c(title.x, title.y)) %>%
dplyr::select(-c(contains('.y')))
names(doi_refs) <- sub('.x', '', names(doi_refs))
#lookup abstract
doi_refs <- doi_refs %>%
dplyr::left_join(df1, by = c("doi")) %>%
dplyr::mutate(abstract = ifelse(is.na(abstract.x), abstract.y, abstract.x)) %>%
dplyr::select(-c(abstract.x, abstract.y)) %>%
dplyr::select(-c(contains('.y')))
names(doi_refs) <- sub('.x', '', names(doi_refs))
#lookup journal
doi_refs <- doi_refs %>%
dplyr::left_join(df1, by = c("doi")) %>%
dplyr::mutate(journal = ifelse(is.na(journal.x), journal.y, journal.x)) %>%
dplyr::select(-c(journal.x, journal.y)) %>%
dplyr::select(-c(contains('.y')))
names(doi_refs) <- sub('.x', '', names(doi_refs))
#lookup publisher
doi_refs <- doi_refs %>%
dplyr::left_join(df1, by = c("doi")) %>%
dplyr::mutate(publisher = ifelse(is.na(publisher.x), publisher.y, publisher.x)) %>%
dplyr::select(-c(publisher.x, publisher.y)) %>%
dplyr::select(-c(contains('.y')))
names(doi_refs) <- sub('.x', '', names(doi_refs))
#lookup volume
doi_refs <- doi_refs %>%
dplyr::left_join(df1, by = c("doi")) %>%
dplyr::mutate(volume = ifelse(is.na(volume.x), volume.y, volume.x)) %>%
dplyr::select(-c(volume.x, volume.y)) %>%
dplyr::select(-c(contains('.y')))
names(doi_refs) <- sub('.x', '', names(doi_refs))
#lookup issue
doi_refs <- doi_refs %>%
dplyr::left_join(df1, by = c("doi")) %>%
dplyr::mutate(issue = ifelse(is.na(issue.x), issue.y, issue.x)) %>%
dplyr::select(-c(issue.x, issue.y)) %>%
dplyr::select(-c(contains('.y')))
names(doi_refs) <- sub('.x', '', names(doi_refs))
#lookup start_page
doi_refs <- doi_refs %>%
dplyr::left_join(df1, by = c("doi")) %>%
dplyr::mutate(start_page = ifelse(is.na(start_page.x), start_page.y, start_page.x)) %>%
dplyr::select(-c(start_page.x, start_page.y)) %>%
dplyr::select(-c(contains('.y')))
names(doi_refs) <- sub('.x', '', names(doi_refs))
#lookup end_page
doi_refs <- doi_refs %>%
dplyr::left_join(df1, by = c("doi")) %>%
dplyr::mutate(end_page = ifelse(is.na(end_page.x), end_page.y, end_page.x)) %>%
dplyr::select(-c(end_page.x, end_page.y)) %>%
dplyr::select(-c(contains('.y')))
names(doi_refs) <- sub('.x', '', names(doi_refs))
#lookup url
doi_refs <- doi_refs %>%
dplyr::left_join(df1, by = c("doi")) %>%
dplyr::mutate(url = ifelse(is.na(url.x), url.y, url.x)) %>%
dplyr::select(-c(url.x, url.y)) %>%
dplyr::select(-c(contains('.y')))
names(doi_refs) <- sub('.x', '', names(doi_refs))
#reorder columns
doi_refs <- doi_refs[, c("intID", "source_type", "author", "year", "title", "journal", "volume", "issue", "start_page", "end_page", "abstract", "doi",
"publisher", "url")]
#data frame containing duplicates for selection
duplicate_dois <- doi_refs[duplicated(doi_refs$doi) | duplicated(doi_refs$doi, fromLast = TRUE), ]
}
####End DOI section####
####Title section####
#subset records without doi missing information but with a title
title_refs <- subset(missing_refs, (is.na(doi)==TRUE & is.na(title)==FALSE))
if(nrow(title_refs)==0){
title_refs <- NULL
} else {
####Search Open Alex for titles####
#find missing records with title on Open Alex
#search on remaining titles
title_input <- data.frame(ids = title_refs$title,
type = 'title')
df2 <- data.frame()
for (i in 1:length(title_input$ids)){
query_work <- oaQueryBuild(
identifier = NULL,
entity = "works",
filter=paste0('title.search:', title_input$ids[i]),
search=NULL,
sort="relevance_score:desc",
endpoint = "https://api.openalex.org/"
)
res <- oaApiRequest(
query_url = query_work
)
if(length(unlist(res))==0){
new_row <- data.frame(id='not found', TI=title_input$ids[i])
df2 <- dplyr::bind_rows(df2, new_row)
} else {
df2 <- dplyr::bind_rows(df2, oa2df(res, entity = "works"))
}
}
#rename result dataframe columns to match inputs
names(df2) <- sub('TI', 'title', names(df2))
names(df2) <- sub('AB', 'abstract', names(df2))
names(df2) <- sub('SO', 'journal', names(df2))
names(df2) <- sub('PU', 'publisher', names(df2))
names(df2) <- sub('PY', 'year', names(df2))
names(df2) <- sub('DI', 'doi', names(df2))
names(df2) <- sub('DT', 'source_type', names(df2))
names(df2) <- sub('volume', 'volume', names(df2))
names(df2) <- sub('issue', 'issue', names(df2))
names(df2) <- sub('first_page', 'start_page', names(df2))
names(df2) <- sub('last_page', 'end_page', names(df2))
names(df2) <- sub('URL', 'url', names(df2))
#if nothing found, move on
if(identical(sum(df2 == 'not found'), nrow(df2)) == TRUE){
title_refs <- NULL
} else {
#remove df$doi URL stem
df2$doi <- gsub('https://doi.org/', '', df2$doi)
#remove irrelevant columns from df2 results
df2 <- dplyr::select(df2, c(author, year, title, journal, volume, issue, start_page, end_page, publisher, doi, abstract, source_type, url))
#remove compltete duplicates
df2 <- df2[!duplicated(df2), ]
#collapse authors list
new_author <- list()
for (i in 1:length(df2$author)) {
new_author <- unlist(c(new_author, paste0(df2$author[[i]]$au_name, collapse = '; ')))
}
df2$author <- new_author
#replace empty abstracts with NA to avoid replacing in the output
df2[df2==""]=NA
####End Search Open Alex for titles####
####lookup and replace based on titles####
#lookup missing information
#lookup authors
title_refs <- title_refs %>%
dplyr::left_join(df2, by = c("title")) %>%
dplyr::mutate(author = ifelse(is.na(author.x), author.y, author.x)) %>%
dplyr::select(-c(author.x, author.y)) %>%
dplyr::select(-c(contains('.y')))
names(title_refs) <- sub('.x', '', names(title_refs))
title_refs <- title_refs[!duplicated(title_refs), ]
#lookup doi
title_refs <- title_refs %>%
dplyr::left_join(df2, by = c("title")) %>%
dplyr::mutate(doi = ifelse(is.na(doi.x), doi.y, doi.x)) %>%
dplyr::select(-c(doi.x, doi.y)) %>%
dplyr::select(-c(contains('.y')))
names(title_refs) <- sub('.x', '', names(title_refs))
title_refs <- title_refs[!duplicated(title_refs), ]
#lookup abstract
title_refs <- title_refs %>%
dplyr::left_join(df2, by = c("title")) %>%
dplyr::mutate(abstract = ifelse(is.na(abstract.x), abstract.y, abstract.x)) %>%
dplyr::select(-c(abstract.x, abstract.y)) %>%
dplyr::select(-c(contains('.y')))
names(title_refs) <- sub('.x', '', names(title_refs))
title_refs <- title_refs[!duplicated(title_refs), ]
#lookup journal
title_refs <- title_refs %>%
dplyr::left_join(df2, by = c("title")) %>%
dplyr::mutate(journal = ifelse(is.na(journal.x), journal.y, journal.x)) %>%
dplyr::select(-c(journal.x, journal.y)) %>%
dplyr::select(-c(contains('.y')))
names(title_refs) <- sub('.x', '', names(title_refs))
title_refs <- title_refs[!duplicated(title_refs), ]
#lookup publisher
title_refs <- title_refs %>%
dplyr::left_join(df2, by = c("title")) %>%
dplyr::mutate(publisher = ifelse(is.na(publisher.x), publisher.y, publisher.x)) %>%
dplyr::select(-c(publisher.x, publisher.y)) %>%
dplyr::select(-c(contains('.y')))
names(title_refs) <- sub('.x', '', names(title_refs))
title_refs <- title_refs[!duplicated(title_refs), ]
#lookup volume
title_refs <- title_refs %>%
dplyr::left_join(df2, by = c("title")) %>%
dplyr::mutate(volume = ifelse(is.na(volume.x), volume.y, volume.x)) %>%
dplyr::select(-c(volume.x, volume.y)) %>%
dplyr::select(-c(contains('.y')))
names(title_refs) <- sub('.x', '', names(title_refs))
title_refs <- title_refs[!duplicated(title_refs), ]
#lookup issue
title_refs <- title_refs %>%
dplyr::left_join(df2, by = c("title")) %>%
dplyr::mutate(issue = ifelse(is.na(issue.x), issue.y, issue.x)) %>%
dplyr::select(-c(issue.x, issue.y)) %>%
dplyr::select(-c(contains('.y')))
names(title_refs) <- sub('.x', '', names(title_refs))
title_refs <- title_refs[!duplicated(title_refs), ]
#lookup start_page
title_refs <- title_refs %>%
dplyr::left_join(df2, by = c("title")) %>%
dplyr::mutate(start_page = ifelse(is.na(start_page.x), start_page.y, start_page.x)) %>%
dplyr::select(-c(start_page.x, start_page.y)) %>%
dplyr::select(-c(contains('.y')))
names(title_refs) <- sub('.x', '', names(title_refs))
title_refs <- title_refs[!duplicated(title_refs), ]
#lookup end_page
title_refs <- title_refs %>%
dplyr::left_join(df2, by = c("title")) %>%
dplyr::mutate(end_page = ifelse(is.na(end_page.x), end_page.y, end_page.x)) %>%
dplyr::select(-c(end_page.x, end_page.y)) %>%
dplyr::select(-c(contains('.y')))
names(title_refs) <- sub('.x', '', names(title_refs))
#lookup url
title_refs <- title_refs %>%
dplyr::left_join(df2, by = c("title")) %>%
dplyr::mutate(url = ifelse(is.na(url.x), url.y, url.x)) %>%
dplyr::select(-c(url.x, url.y)) %>%
dplyr::select(-c(contains('.y')))
names(title_refs) <- sub('.x', '', names(title_refs))
#remove duplicates
title_refs <- title_refs[!duplicated(title_refs), ]
#reorder columns
title_refs <- title_refs[, c("intID", "source_type", "author", "year", "title", "journal", "volume", "issue", "start_page", "end_page", "abstract", "doi",
"publisher", "url")]
#coalesce partial duplicated columns, merging rows sharing partial data
title_refs <- title_refs %>%
dplyr::group_by(intID) %>%
dplyr::summarise_all(coalesce_by_column)
#data frame containing duplicates for selection
duplicate_titles <- title_refs[duplicated(title_refs$title) | duplicated(title_refs$title, fromLast = TRUE), ]
}
####End title section####
}
#bind doi lookup and title lookup table with original values not missing information
result <- dplyr::bind_rows(non_missing, doi_refs, title_refs)
#merge in original columns to supplement returns from OpenAlex
result$intID <- as.numeric(result$intID)
#the folllowing doens't work - it's merging incorrectly
intermediate <- result %>%
dplyr::left_join(orig_refs, by = c("intID")) %>%
dplyr::select(-c(contains('.y')))
names(intermediate) <- sub('.x', '', names(intermediate))
#bind intermediate output with original references
intermediate <- bind_rows(intermediate, orig_refs)
#coalesce to gap-fill from original references where there is a missing value in the intermediate output
output <- intermediate %>%
dplyr::group_by(intID) %>%
dplyr::summarise_all(coalesce_by_column)
View(output)
View(refs)
runApp('inst/shiny-examples/bibfix')
runApp('inst/shiny-examples/bibfix')
runApp('inst/shiny-examples/bibfix')
runApp('inst/shiny-examples/bibfix')
runApp('inst/shiny-examples/bibfix')
runApp('inst/shiny-examples/bibfix')
runApp('inst/shiny-examples/bibfix')
file <- file.choose()
refs <- synthesisr::read_refs(file)
View(refs)
shiny::runApp('inst/shiny-examples/bibfix')
runApp('inst/shiny-examples/bibfix')
runApp('inst/shiny-examples/bibfix')
runApp('inst/shiny-examples/bibfix')
runApp('inst/shiny-examples/bibfix')
setwd("~/OneDrive - SEI/ESHackathon/4.Remote 2020/bibfix/inst/shiny-examples/bibfix")
rsconnect::deployApp()
runApp()
runApp()
runApp()
runApp()
runApp()
rsconnect::deployApp()
token = 'o7kaHxldVwbQxgo32RDfKGbG8g0rivnqFDxpQyx6NAzGKsavm2lN'
input <- data.frame(ids = c('10.1371/journal.pone.0138237', '10.1186/s13750-016-0059-6', 'The role of tourism and recreation in the spread of non-native species: a systematic review and meta-analysis'),
type = c('doi', 'doi', 'title'))
source('functions.R')
source('mixed_id_wrapper.R')
setwd("~/OneDrive - SEI/ESHackathon/4.Remote 2020/bibfix/inst/shiny-examples/bibfix")
source('functions.R')
source('mixed_id_wrapper.R')
result <- get_refs_mixed(input,
search = 'input',
token = 'o7kaHxldVwbQxgo32RDfKGbG8g0rivnqFDxpQyx6NAzGKsavm2lN')
library(data.table)
result <- get_refs_mixed(input,
search = 'input',
token = 'o7kaHxldVwbQxgo32RDfKGbG8g0rivnqFDxpQyx6NAzGKsavm2lN')
View(result)
result[["df"]]
x <- result[["df"]]
View(x)
